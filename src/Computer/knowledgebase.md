# 知识库

知识工程的目标是建议可供计算机使用的知识库。

> The acquisition of knowledge is always of use to the intellect, because it may thus drive out useless things and retain the good. For nothing can be loved or hated unless it is first known.

A knowledge map is a graphical representation of concepts that reveals the relationships and dependencies among the concepts. Knowledge maps are cognitive aids designed to help users explore a body of knowledge in a nonlinear way.

A knowledge map primarily serves as a reference tool while a concept map serves as a learning tool.

A problem with knowledge maps is that the large number of relationships between the concepts produces a large number of intertwined and crisscrossing edges in the graph. In turn, it is difficult to interpret the conceptual relationships.

## 记忆

记忆构成三大部分：实体集合、空间集合、时间集合。

每个实体集合都包含 4 种属性：1. 时间，2. 空间，3. 函数，4. 附资料, 严格的说每个集合不存在下面有资料的说法，因为集合的子集与资料冲突了，之所以在每个集合上加资料属性，是因为数据量太恐怖。函数即 AI 的思维逻辑，世界上每个人或物都有着自己的逻辑。

## 语言

语言和知识是密切相关的。我们看到的语言只是冰山上的一小角，就是我们说的话。但是你如果想理解这句话，跟这句话相关的背景知识就像冰山下面这一大块。语言文字不可能完全表达出思维，只能激活思维。

> 语用 = 语义 + 语境（环境、上下文、知识）

语境包括：
1、物理语境。包括（1）时间、地点、场所，这个场所是指在车里或在家里等等。（2）天气。（3）情绪和情感。（4）设备上面显示的内容。（5）设备能感知到的信息，比如我们和空调对话，空调能够感知到室内外的温度、湿度。这个语境的生命周期是请求级的。
2、言语语境。（1）上下文，设备上和设备上面反馈的信息也是一种上下文，这个生命周期可以看成是会话级的。
3、知识语境。包括：（1）人类的常识和领域知识。（2）用户画像，包括说话人的一些基本信息，用户的性别、年龄、文化水平、爱好等等。（3）Agent 画像，就是这个机器人定义的信息，像小冰把它的 Agent 画像定义为一个 18 岁的邻家小妹。（4）设备信息库，如果把音箱作为中控的话，中控连接的设备信息、设备状态等都是语境。

## 人机对话

VUI：Voice-UI，语音的优势是输入很便捷，缺点是输出很低效。Amazon Echo Show 是 VUI+GUI，把两者优势做了整合，VUI 用来做输入，GUI 用来做输出。有遥控器的地方就可以用语音来交互。另外一个应用场景是车载。

人机对话：语音识别 → 语义理解 → 对话管理 → 自然语言生成 → 语音合成

我们目前跟音箱的交互都是先唤醒，说「小爱同学，给我点首歌」，又说「小爱同学，播放下一首」。非常麻烦，但人和人对话是不会总频繁叫人的名字的，这时候就需要流式对话，这块的技术难点是怎么判断一个人说话是不是说完了，你是否可以打断，这是目前技术上最难的一点。

## 知识图谱

世界是由事物组成的，物是对象，事是事实，知识图谱的本质就是对“事实”的表述和记录，即：用对象及其关系的语言符号来描述客观世界的逻辑结构的图景。知识图谱最重要的概念就是「Things，Not Strings」。

人工智能的“符号主义学派”的技术路线在发展中遇到了将人类知识形式化的困难，以及符号运算“组合爆炸”的问题局限。这一局限被人工智能的“连接主义学派”在机器学习方面的突破得以弥补，这个突破就是基于卷积神经网络的深度学习算法。

可以用三元组构成知识图谱，三元组是由实体、属性和关系组成的（Entity、Attribute、Relation）。

具体表示方法为：<实体 1 关系 实体 2>，或者<实体 属性 属性值>。

举个例子，“达观数据是一家人工智能公司”，其实就可以表示成这样的三元组：
<达观数据，is-a，人工智能公司>。

“人工智能公司是一种高科技公司” 可以表示成：
<人工智能公司，subclass, 高科技公司>。

“达观数据成立于 2015 年”，也可以把这个属性表示成一个三元组，就是：
<达观数据，start-time，2015 年>。

基于已有的三元组，它可以推导出新的关系，这个对构建知识图谱来说是非常重要的。我们知道，知识图谱要有丰富的实体关系，才能真正达到它实用的价值。完全靠人工去做的话是不太现实的，所以内部一定有一个自动推理的机制，可以不断的去推理出新的关系数据出来，不断的丰富知识图谱。

来看一些具体的例子。

“人工智能公司是一种高科技公司”，subclass 的关系。

还有一个三元组是谷歌是一家人工智能公司，<Google is-a 人工智能公司>，可以由这两个三元组推导出谷歌是一家高科技公司，<Google is-a 高科技公司 >。因为 subclass 的实例之间是一种继承的关系。

<翅膀 part-of 鸟>，< 麻雀 kind-of 鸟 >，可以推导出 < 翅膀 part-of 麻雀 >。

本体构建的方法从大的面来讲有两种，一种是传统基于专家的方法，就是请一些专家全手工构建，他们对每个词、每个实体、词之间的关系都开会讨论，最后决定应该这样、应该那样，这是专家驱动的方法。但这种方法已经不太可行，而且这种方法也会成为我们做知识图谱的瓶颈，因为我们期望知识图谱是一个敏捷构建的。

目前大部分是数据驱动的方法，就是我们通过数据挖掘去自动构建知识图谱，适当地基于人工的 review。前端应用不能假设整个知识图谱是完全正确的、完整的。我们可以通过快速迭代，不断的对知识图谱去做更新，然后根据自动化的测试或者根据人工的抽样检查和应用的效果去看知识图谱的质量。

知识图谱分成两大类，一类叫 Common Sense Knowledge Graph（常识知识图谱），另外一类叫 Encyclopedia Knowledge Graph（百科全书知识图谱）。

对于 Common Sense Knowledge Graph 通常带有一定的概率，但是 Encyclopedia Knowledge Graph 通常就是 “非黑即白”，那么构建这种知识图谱时，我们在乎的就是 Precision（准确率）。

### 融合知识的话语理解

第一步要做实体的发现与链接，例如，「你喜欢谢霆锋吗」，我们要把谢霆锋跟知识图谱的实体关联起来。

实体发现是发现文本中提到(Mention)了哪些实体，实体链接是把这个 Mention 和知识图谱里的实体关联起来。知识图谱里的实体关于「苹果」可能有多个实体，有苹果公司，还有苹果这个品牌，还可能是苹果手机、苹果电脑，还有水果叫苹果等等，这里的「苹果」到底指哪个呢？可能要靠上下文的判断。对候选实体排序，返回一个最可能的实体。

第二步做指代发现，比如「你知道他女朋友是谁」，那这个「他」到底是指谁，我们首先要发现他是一个指代词，然后再根据上下文去判断「他」在这个例子里面是谢霆锋这个实体。

另外，我们做语义理解还有一种情况是结合知识做消歧义。比如用户说「周巧文的生日」，因为《生日》是一首歌的名字，周巧文是这个歌的歌手，这时候我们理解它是个音乐。但如果又问一下「刘德华的生日」，通过知识的验证知道刘德华并没有唱过这首歌，这时候要转成问答，直接返回他的生日，说「刘德华的生日是 1961 年 9 月 27 日」。
